{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b903f96",
   "metadata": {},
   "source": [
    "### 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f073e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2c1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of Bearer Token\n",
    "\n",
    "os.environ['TOKEN'] = 'AAAAAAAAAAAAAAAAAAAAAOY3eQEAAAAA%2FK0FPI1vVnopel6JTVkr3Xub%2BlE%3Dpbokl1iPkF9foae0YEnAfsmUBt2jsF0DMss8nvElve8Z8dhoVL'\n",
    "# os.environ['TOKEN'] = 'AAAAAAAAAAAAAAAAAAAAAIu3dQEAAAAAv%2Bz8dWQYjA0ZOWHJlcu%2FFIUiFjA%3Dn54h9wPaU6iRsCwWKAlanfprENYSf98Rbups3bltouPpdDULUf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596fc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auth function to retrieve the bearer token from the environment\n",
    "\n",
    "def auth():\n",
    "    return os.getenv('TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7acc111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating headers\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c3a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating URLs\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1483bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "891066ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv_updated(json_response, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Author ID\n",
    "        author_id = tweet['author_id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "\n",
    "        # 3. Geolocation\n",
    "        if ('geo' in tweet):   \n",
    "            geo = tweet['geo']['place_id']\n",
    "        else:\n",
    "            geo = \" \"\n",
    "\n",
    "        # 4. Tweet ID\n",
    "        tweet_id = tweet['id']\n",
    "\n",
    "        # 5. Language\n",
    "        lang = tweet['lang']\n",
    "\n",
    "        # 6. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "\n",
    "        # 7. source\n",
    "        source = tweet['source']\n",
    "\n",
    "        # 8. Tweet text\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # 9. Possibly sensitive\n",
    "        reply_settings = tweet['reply_settings']\n",
    "        \n",
    "        # 10. Conversation id \n",
    "        conversation_id = tweet['conversation_id']\n",
    "        \n",
    "        # 11. Referenced tweets type\n",
    "        if ('referenced_tweets' in tweet):\n",
    "            referenced_tweets_type = tweet['referenced_tweets']\n",
    "        else:\n",
    "            referenced_tweets_type = \"\"\n",
    "        \n",
    "        # 12. Referenced tweets id\n",
    "        if ('referenced_tweets' in tweet):\n",
    "            referenced_tweets_id = tweet['referenced_tweets']\n",
    "        else:\n",
    "            referenced_tweets_id = \"\"\n",
    "        \n",
    "        # 13. Reply to\n",
    "        if ('in_reply_to_user_id' in tweet):\n",
    "            in_reply_to_user_id = tweet['in_reply_to_user_id']\n",
    "        else:\n",
    "            in_reply_to_user_id = \"\"\n",
    "        \n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [author_id, created_at, geo, tweet_id, lang, like_count, quote_count, reply_count, retweet_count,\\\n",
    "               source, text, reply_settings, conversation_id, referenced_tweets_type, referenced_tweets_id, \\\n",
    "               in_reply_to_user_id]\n",
    "        \n",
    "       \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96d448f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data0208_123009.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "now = datetime.now()\n",
    "current_datetime = now.strftime(\"%d%m_%H%M%S\")\n",
    "filename = 'data' + current_datetime + '.csv'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6417250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3j426xzdxdo2y5ycm7k4x0ej3a7p9\n",
      "Start Date:  2017-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  490\n",
      "Total # of Tweets added:  490\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3j71yw5bazyho8uxq3qs0yktjfcsd\n",
      "Start Date:  2017-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  488\n",
      "Total # of Tweets added:  978\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3ja2kwxtiz7qu4kvt2ra07kxqovb1\n",
      "Start Date:  2017-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  489\n",
      "Total # of Tweets added:  1467\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3jd2da20ogafd2kpfloh22196ifel\n",
      "Start Date:  2017-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  471\n",
      "Total # of Tweets added:  1938\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3jg2z2ciz06ure59j1v1smq8efnul\n",
      "Start Date:  2017-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  496\n",
      "Total # of Tweets added:  2434\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3jlyqdsplkntxnu1vmwonmz3yle9p\n",
      "Start Date:  2017-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  490\n",
      "Total # of Tweets added:  2924\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw3joyxhlrvvyfcuxejzaicvsadzam5\n",
      "Start Date:  2017-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  488\n",
      "Total # of Tweets added:  3412\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw448fpdbn11l92x500ou1upd9hdm65\n",
      "Start Date:  2017-08-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  487\n",
      "Total # of Tweets added:  3899\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44bfhqcujd2skxz8hlccdk2seabul\n",
      "Start Date:  2017-09-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  475\n",
      "Total # of Tweets added:  4374\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44eg3ip4xp14qdese0u5balx5bekd\n",
      "Start Date:  2017-10-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  483\n",
      "Total # of Tweets added:  4857\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44hgaqr28f057kldzbzhem0x2wqyl\n",
      "Start Date:  2017-11-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  492\n",
      "Total # of Tweets added:  5349\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44kghwm582wodfd7097lut1pt6ikd\n",
      "Start Date:  2017-12-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  483\n",
      "Total # of Tweets added:  5832\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44ngow79aesucqgtx6q7clfuf64ql\n",
      "Start Date:  2018-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  465\n",
      "Total # of Tweets added:  6297\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44qggs7juu4ywjuo4pbz9cry9cq65\n",
      "Start Date:  2018-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  481\n",
      "Total # of Tweets added:  6778\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44th2ot06knst9dinnsax7kjygcql\n",
      "Start Date:  2018-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  483\n",
      "Total # of Tweets added:  7261\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  1jzu9lk96gu5npw44zcu4j8ll27krc8rr56qvsjo7n99\n",
      "Start Date:  2018-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  491\n",
      "Total # of Tweets added:  7752\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0am0vgs06t5eg96eaasu4k6yypod\n",
      "Start Date:  2018-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  485\n",
      "Total # of Tweets added:  8237\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0dm81do5jwcokvchzvmwo188tgfx\n",
      "Start Date:  2018-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  485\n",
      "Total # of Tweets added:  8722\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0gmfbit9uf6md55qu6vq0s6s9u9p\n",
      "Start Date:  2018-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  490\n",
      "Total # of Tweets added:  9212\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0jmmd8218gt1wbetlgcv4h4ia7p9\n",
      "Start Date:  2018-08-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  482\n",
      "Total # of Tweets added:  9694\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0mmt6bzmq0pdv8ysgtfu6klsisu5\n",
      "Start Date:  2018-09-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  485\n",
      "Total # of Tweets added:  10179\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0pn0gimnnfdekcresnc58rwnyhkt\n",
      "Start Date:  2018-10-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  480\n",
      "Total # of Tweets added:  10659\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0snmd2vklrz8oyxsj147gzyz4igt\n",
      "Start Date:  2018-11-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  492\n",
      "Total # of Tweets added:  11151\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn0vntclw5gw2ra0e9dtpbrzbg79fh\n",
      "Start Date:  2018-12-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  484\n",
      "Total # of Tweets added:  11635\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fn11jko2ocvw6i9fibk8ea0ihesmf1\n",
      "Start Date:  2019-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  483\n",
      "Total # of Tweets added:  12118\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnlkzxkioghlbwp8vfk31pr7l1uu0t\n",
      "Start Date:  2019-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  487\n",
      "Total # of Tweets added:  12605\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnlo04sj3n1owgujtz31ejic8lrkal\n",
      "Start Date:  2019-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  475\n",
      "Total # of Tweets added:  13080\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnlr0bntk5xuyz1mfm7xkdc0o3jm2l\n",
      "Start Date:  2019-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  482\n",
      "Total # of Tweets added:  13562\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnlu0j0286sqvbbmy51u4gavzyuu7x\n",
      "Start Date:  2019-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  485\n",
      "Total # of Tweets added:  14047\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnlx0pr4fboo5e75nqqgcigjsynfr1\n",
      "Start Date:  2019-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  476\n",
      "Total # of Tweets added:  14523\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnm00wz3y1y1lvsq4x67gl6mepvtrx\n",
      "Start Date:  2019-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  475\n",
      "Total # of Tweets added:  14998\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnm31499e36y8hipmdu8uu2malovwd\n",
      "Start Date:  2019-08-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  444\n",
      "Total # of Tweets added:  15442\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnm61b2g0pjc8npnhcpq5yumforkvx\n",
      "Start Date:  2019-09-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  458\n",
      "Total # of Tweets added:  15900\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fnm91icm2j7gudg6vph4n42wt31qbh\n",
      "Start Date:  2019-10-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  446\n",
      "Total # of Tweets added:  16346\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo6ve98rqrgp6lv5yb4s1k1vkvhv25\n",
      "Start Date:  2019-11-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  480\n",
      "Total # of Tweets added:  16826\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo6yegcipltm3zzv9aqlolu95izypp\n",
      "Start Date:  2019-12-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  477\n",
      "Total # of Tweets added:  17303\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo71enkjfd6wuys17ts5qvvc7ckm7x\n",
      "Start Date:  2020-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  439\n",
      "Total # of Tweets added:  17742\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo74eudo9diwon6s2mpcas744byqnx\n",
      "Start Date:  2020-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  460\n",
      "Total # of Tweets added:  18202\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo77f1fboxn067okf65xm6hnjiuwzh\n",
      "Start Date:  2020-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  468\n",
      "Total # of Tweets added:  18670\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo7af8l730dht49klpj7bn9o5iz1bx\n",
      "Start Date:  2020-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  467\n",
      "Total # of Tweets added:  19137\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo7dffp05jrgagcgl0ofhdxh6q803h\n",
      "Start Date:  2020-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  468\n",
      "Total # of Tweets added:  19605\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo7gfmk9perry2q6742rqx0drtrwxp\n",
      "Start Date:  2020-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  448\n",
      "Total # of Tweets added:  20053\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo7jftwioe6vlopsv8qnyu2nzs7dkt\n",
      "Start Date:  2020-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  463\n",
      "Total # of Tweets added:  20516\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo7mg0y87zgzyxnttob8vvrdhx47zx\n",
      "Start Date:  2020-08-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  386\n",
      "Total # of Tweets added:  20902\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fos8sdc71lkq9uhawolu30kdf57wjh\n",
      "Start Date:  2020-09-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  428\n",
      "Total # of Tweets added:  21330\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosbskfz79il6pvpa5pnq2j0xjejy5\n",
      "Start Date:  2020-10-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  393\n",
      "Total # of Tweets added:  21723\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosesrde33tkghe603rw030gj2oynx\n",
      "Start Date:  2020-11-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  450\n",
      "Total # of Tweets added:  22173\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3foshtd7vewl2kzvxyz0fnju8scvxbx\n",
      "Start Date:  2020-12-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  438\n",
      "Total # of Tweets added:  22611\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosktkfux94x8att2ou7y19x25vkal\n",
      "Start Date:  2021-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  351\n",
      "Total # of Tweets added:  22962\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosntce1g64ecr93ehdd37osor05tp\n",
      "Start Date:  2021-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  358\n",
      "Total # of Tweets added:  23320\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosqtjo6laehsk2spas20qky2fd56l\n",
      "Start Date:  2021-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  432\n",
      "Total # of Tweets added:  23752\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fosttqlkl224rp2q2o3b82esfu93st\n",
      "Start Date:  2021-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  429\n",
      "Total # of Tweets added:  24181\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3foswtxpbukace7dtwxqe1tthz3aoal\n",
      "Start Date:  2021-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  454\n",
      "Total # of Tweets added:  24635\n",
      "-------------------\n",
      "Total number of results:  24635\n"
     ]
    }
   ],
   "source": [
    "# Modifying the query based on the parameters\n",
    "#Inputs for tweets\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"erectile dysfunction lang:en\"\n",
    "\n",
    "start_list = []\n",
    "end_list = []\n",
    "\n",
    "date = datetime(2017, 1, 1)\n",
    "start_date = date\n",
    "\n",
    "\n",
    "for i in range(53):\n",
    "    start_date_formatted = start_date.isoformat() + '.000Z'\n",
    "    start_list.append(start_date_formatted)\n",
    "\n",
    "    end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "    end_date_formatted = end_date.isoformat() + '.000Z'\n",
    "    end_list.append(end_date_formatted)\n",
    "\n",
    "    start_date += relativedelta(months=1)\n",
    "\n",
    "\n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "csvFile = open(filename, \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', \\\n",
    "                    'reply_count','retweet_count','source','tweet','reply_settings', 'conversation_id', \\\n",
    "                    'referenced_tweets_type', 'referenced_tweets_id', 'in_reply_to_user_id'])\n",
    "csvFile.close()\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    max_count = 100 # Max tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        # Check if max_count reached\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv_updated(json_response, filename)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv_updated(json_response, filename)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df2c6",
   "metadata": {},
   "source": [
    "### 2. Data Wrangling\n",
    "### <ensp> 2.a. Cleaning\n",
    "#### 2.a.i Handling duplicate tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6278e1e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data0108_164439.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\REVATH~1\\AppData\\Local\\Temp/ipykernel_9376/3794586524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data0108_164439.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_ed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data0108_164439.csv'"
     ]
    }
   ],
   "source": [
    "filename = 'data0108_164439.csv'\n",
    "df_ed = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88770d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ed[df_ed.referenced_tweets_type.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Count of tweets for ED: {len(df_ed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83504c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120792a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Count of tweets for ED after removing the duplicates: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a206ab",
   "metadata": {},
   "source": [
    "#### 2.a.ii Hyperlinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbe560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presence(x,text):\n",
    "    if text in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0bac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hyperlink_tag']=df['tweet'].apply(lambda x: presence(x,'http'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hyperlink_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53e1b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b81f49b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\REVATH~1\\AppData\\Local\\Temp/ipykernel_9376/391752096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet_exc_link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\" http\\S+|www.\\S+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet_inc_link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(http\\S+|www.\\S+)\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet_inc_link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet_inc_link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Tweet_exc_link']=df['tweet'].apply(lambda x: re.sub(r\" http\\S+|www.\\S+\", \"\",x))\n",
    "df['Tweet_inc_link']=df['tweet'].apply(lambda x: re.findall(\"(http\\S+|www.\\S+)\",x))\n",
    "df['Tweet_inc_link']=df['Tweet_inc_link'].apply(lambda x: str(x).replace(\"[\",\"\").replace(\"]\",\"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7392e3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>referenced_tweets_type</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>hyperlink_tag</th>\n",
       "      <th>Tweet_exc_link</th>\n",
       "      <th>Tweet_inc_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72687927</td>\n",
       "      <td>2017-01-30 23:59:54+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826218412087058432</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Erectile Dysfunction Download - https://t.co/2...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>826218412087058432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Erectile Dysfunction Download - #iTunes #hypno...</td>\n",
       "      <td>'https://t.co/2DOzGXrbVl'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>810231726396080128</td>\n",
       "      <td>2017-01-30 23:50:19+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826216000412647424</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WordPress.com</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction? h...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>826216000412647424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/B0HqZeMgdy', 'https://t.co/mwnHs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2152440722</td>\n",
       "      <td>2017-01-30 23:45:14+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214720780722176</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction? h...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>826214720780722176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/C0XlVKmnGB', 'https://t.co/4I6fh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2891120914</td>\n",
       "      <td>2017-01-30 23:45:11+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214708512296960</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction? h...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>826214708512296960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/q3RiaKo4HE', 'https://t.co/L2lIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956941058</td>\n",
       "      <td>2017-01-30 23:44:02+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214419982143488</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?\\n...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>826214419982143488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?\\n...</td>\n",
       "      <td>'https://t.co/EG6mffU86k', 'https://t.co/UYAwz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author id                 created_at geo                  id lang  \\\n",
       "0            72687927  2017-01-30 23:59:54+00:00      826218412087058432   en   \n",
       "1  810231726396080128  2017-01-30 23:50:19+00:00      826216000412647424   en   \n",
       "3          2152440722  2017-01-30 23:45:14+00:00      826214720780722176   en   \n",
       "4          2891120914  2017-01-30 23:45:11+00:00      826214708512296960   en   \n",
       "5          1956941058  2017-01-30 23:44:02+00:00      826214419982143488   en   \n",
       "\n",
       "   like_count  quote_count  reply_count  retweet_count              source  \\\n",
       "0           0            0            0              0  Twitter Web Client   \n",
       "1           0            0            0              0       WordPress.com   \n",
       "3           1            0            0              0             dlvr.it   \n",
       "4           1            0            0              0             dlvr.it   \n",
       "5           1            0            0              0               IFTTT   \n",
       "\n",
       "                                               tweet reply_settings  \\\n",
       "0  Erectile Dysfunction Download - https://t.co/2...       everyone   \n",
       "1  Could acupuncture cure erectile dysfunction? h...       everyone   \n",
       "3  Could acupuncture cure erectile dysfunction? h...       everyone   \n",
       "4  Could acupuncture cure erectile dysfunction? h...       everyone   \n",
       "5  Could acupuncture cure erectile dysfunction?\\n...       everyone   \n",
       "\n",
       "      conversation_id referenced_tweets_type referenced_tweets_id  \\\n",
       "0  826218412087058432                    NaN                  NaN   \n",
       "1  826216000412647424                    NaN                  NaN   \n",
       "3  826214720780722176                    NaN                  NaN   \n",
       "4  826214708512296960                    NaN                  NaN   \n",
       "5  826214419982143488                    NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id  hyperlink_tag  \\\n",
       "0                  NaN              1   \n",
       "1                  NaN              1   \n",
       "3                  NaN              1   \n",
       "4                  NaN              1   \n",
       "5                  NaN              1   \n",
       "\n",
       "                                      Tweet_exc_link  \\\n",
       "0  Erectile Dysfunction Download - #iTunes #hypno...   \n",
       "1       Could acupuncture cure erectile dysfunction?   \n",
       "3       Could acupuncture cure erectile dysfunction?   \n",
       "4       Could acupuncture cure erectile dysfunction?   \n",
       "5  Could acupuncture cure erectile dysfunction?\\n...   \n",
       "\n",
       "                                      Tweet_inc_link  \n",
       "0                          'https://t.co/2DOzGXrbVl'  \n",
       "1  'https://t.co/B0HqZeMgdy', 'https://t.co/mwnHs...  \n",
       "3  'https://t.co/C0XlVKmnGB', 'https://t.co/4I6fh...  \n",
       "4  'https://t.co/q3RiaKo4HE', 'https://t.co/L2lIN...  \n",
       "5  'https://t.co/EG6mffU86k', 'https://t.co/UYAwz...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3963f152",
   "metadata": {},
   "source": [
    "#### 2.a.iii Hashtag removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9cd83334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nupur\\AppData\\Local\\Temp/ipykernel_17280/1925447993.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tweet_exc_hash']=df['Tweet_exc_link'].apply(lambda x: x.replace('#','').strip())\n",
      "C:\\Users\\Nupur\\AppData\\Local\\Temp/ipykernel_17280/1925447993.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tweet_hashtag_inc']=df['Tweet_exc_link'].apply(lambda x: re.findall(\"#(\\S+)\",x))\n",
      "C:\\Users\\Nupur\\AppData\\Local\\Temp/ipykernel_17280/1925447993.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tweet_hashtag_inc']=df['Tweet_hashtag_inc'].apply(lambda x: \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "df['Tweet_exc_hash']=df['Tweet_exc_link'].apply(lambda x: x.replace('#','').strip())\n",
    "df['Tweet_hashtag_inc']=df['Tweet_exc_link'].apply(lambda x: re.findall(\"#(\\S+)\",x))\n",
    "df['Tweet_hashtag_inc']=df['Tweet_hashtag_inc'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d5e7e",
   "metadata": {},
   "source": [
    "#### 2.a.iv Removal of \\n, \\t, \\&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "997216c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nupur\\AppData\\Local\\Temp/ipykernel_17280/1711057798.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_formatted'] = df['Tweet_exc_hash'].apply(lambda x: x.replace('&gt;|\\n|\\t', ''))\n"
     ]
    }
   ],
   "source": [
    "df['tweet_formatted'] = df['Tweet_exc_hash'].apply(lambda x: x.replace('&gt;|\\n|\\t', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47b3ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c346ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45b11055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nupur\\AppData\\Local\\Temp/ipykernel_17280/3760804546.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_formatted'] = df['tweet_formatted'].apply(lambda x: emoji.demojize(x))\n"
     ]
    }
   ],
   "source": [
    "df['tweet_formatted'] = df['tweet_formatted'].apply(lambda x: emoji.demojize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48558865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>referenced_tweets_type</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>hyperlink_tag</th>\n",
       "      <th>Tweet_exc_link</th>\n",
       "      <th>Tweet_inc_link</th>\n",
       "      <th>Tweet_exc_hash</th>\n",
       "      <th>Tweet_hashtag_inc</th>\n",
       "      <th>tweet_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72687927</td>\n",
       "      <td>2017-01-30 23:59:54+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826218412087058432</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>...</td>\n",
       "      <td>826218412087058432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Erectile Dysfunction Download - #iTunes #hypno...</td>\n",
       "      <td>'https://t.co/2DOzGXrbVl'</td>\n",
       "      <td>Erectile Dysfunction Download - iTunes hypnoth...</td>\n",
       "      <td>iTunes hypnotherapy</td>\n",
       "      <td>Erectile Dysfunction Download - iTunes hypnoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>810231726396080128</td>\n",
       "      <td>2017-01-30 23:50:19+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826216000412647424</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WordPress.com</td>\n",
       "      <td>...</td>\n",
       "      <td>826216000412647424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/B0HqZeMgdy', 'https://t.co/mwnHs...</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td></td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2152440722</td>\n",
       "      <td>2017-01-30 23:45:14+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214720780722176</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>...</td>\n",
       "      <td>826214720780722176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/C0XlVKmnGB', 'https://t.co/4I6fh...</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td></td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2891120914</td>\n",
       "      <td>2017-01-30 23:45:11+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214708512296960</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>...</td>\n",
       "      <td>826214708512296960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td>'https://t.co/q3RiaKo4HE', 'https://t.co/L2lIN...</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "      <td></td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956941058</td>\n",
       "      <td>2017-01-30 23:44:02+00:00</td>\n",
       "      <td></td>\n",
       "      <td>826214419982143488</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>...</td>\n",
       "      <td>826214419982143488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?\\n...</td>\n",
       "      <td>'https://t.co/EG6mffU86k', 'https://t.co/UYAwz...</td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?\\n...</td>\n",
       "      <td></td>\n",
       "      <td>Could acupuncture cure erectile dysfunction?\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author id                 created_at geo                  id lang  \\\n",
       "0            72687927  2017-01-30 23:59:54+00:00      826218412087058432   en   \n",
       "1  810231726396080128  2017-01-30 23:50:19+00:00      826216000412647424   en   \n",
       "3          2152440722  2017-01-30 23:45:14+00:00      826214720780722176   en   \n",
       "4          2891120914  2017-01-30 23:45:11+00:00      826214708512296960   en   \n",
       "5          1956941058  2017-01-30 23:44:02+00:00      826214419982143488   en   \n",
       "\n",
       "   like_count  quote_count  reply_count  retweet_count              source  \\\n",
       "0           0            0            0              0  Twitter Web Client   \n",
       "1           0            0            0              0       WordPress.com   \n",
       "3           1            0            0              0             dlvr.it   \n",
       "4           1            0            0              0             dlvr.it   \n",
       "5           1            0            0              0               IFTTT   \n",
       "\n",
       "   ...     conversation_id referenced_tweets_type  referenced_tweets_id  \\\n",
       "0  ...  826218412087058432                    NaN                   NaN   \n",
       "1  ...  826216000412647424                    NaN                   NaN   \n",
       "3  ...  826214720780722176                    NaN                   NaN   \n",
       "4  ...  826214708512296960                    NaN                   NaN   \n",
       "5  ...  826214419982143488                    NaN                   NaN   \n",
       "\n",
       "  in_reply_to_user_id hyperlink_tag  \\\n",
       "0                 NaN             1   \n",
       "1                 NaN             1   \n",
       "3                 NaN             1   \n",
       "4                 NaN             1   \n",
       "5                 NaN             1   \n",
       "\n",
       "                                      Tweet_exc_link  \\\n",
       "0  Erectile Dysfunction Download - #iTunes #hypno...   \n",
       "1       Could acupuncture cure erectile dysfunction?   \n",
       "3       Could acupuncture cure erectile dysfunction?   \n",
       "4       Could acupuncture cure erectile dysfunction?   \n",
       "5  Could acupuncture cure erectile dysfunction?\\n...   \n",
       "\n",
       "                                      Tweet_inc_link  \\\n",
       "0                          'https://t.co/2DOzGXrbVl'   \n",
       "1  'https://t.co/B0HqZeMgdy', 'https://t.co/mwnHs...   \n",
       "3  'https://t.co/C0XlVKmnGB', 'https://t.co/4I6fh...   \n",
       "4  'https://t.co/q3RiaKo4HE', 'https://t.co/L2lIN...   \n",
       "5  'https://t.co/EG6mffU86k', 'https://t.co/UYAwz...   \n",
       "\n",
       "                                      Tweet_exc_hash    Tweet_hashtag_inc  \\\n",
       "0  Erectile Dysfunction Download - iTunes hypnoth...  iTunes hypnotherapy   \n",
       "1       Could acupuncture cure erectile dysfunction?                        \n",
       "3       Could acupuncture cure erectile dysfunction?                        \n",
       "4       Could acupuncture cure erectile dysfunction?                        \n",
       "5  Could acupuncture cure erectile dysfunction?\\n...                        \n",
       "\n",
       "                                     tweet_formatted  \n",
       "0  Erectile Dysfunction Download - iTunes hypnoth...  \n",
       "1       Could acupuncture cure erectile dysfunction?  \n",
       "3       Could acupuncture cure erectile dysfunction?  \n",
       "4       Could acupuncture cure erectile dysfunction?  \n",
       "5  Could acupuncture cure erectile dysfunction?\\n...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d83fe552",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5eb75218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps for text cleaning \n",
    "\n",
    "df = df.astype(str)\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def text_cleaning(x):\n",
    "    norm_text = x[0].upper() + x[1:] # Step I. Normalizing text\n",
    "    for word in norm_text.split(): # Step II. Handling the contraction text\n",
    "        if word.lower() in contractions:\n",
    "            norm_text = norm_text.replace(word, contractions[word.lower()])\n",
    "    rem_unicode = re.sub(r\"[^-a-zA-Z0-9 /,:]+\", \"\", norm_text) #Step III. Removing Unicode Characters\n",
    "#     rem_unicode = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", norm_text) # Step III. Removing unicode characters\n",
    "    return rem_unicode\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "df['tweet_formatted'] = df['tweet_formatted'].apply(text_cleaning)\n",
    "df['tweet_formatted'] = df['tweet_formatted'].apply(lambda x: spell.correction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85ba0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Tweets_formatted_08012022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e813fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9881d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=pd.read_excel(r\"C:\\Users\\Revathi P\\Documents\\Graduate Research - Twitter Analysis\\Datasets\\Latest\\data2207_094933.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba68af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>referenced_tweets_type</th>\n",
       "      <th>referenced_tweets_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.300559e+09</td>\n",
       "      <td>2017-01-29 23:59:55+00:00</td>\n",
       "      <td></td>\n",
       "      <td>8.258560e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I have erectile dysfunction â˜¹ï¸_x008f_</td>\n",
       "      <td>everyone</td>\n",
       "      <td>8.258560e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.670847e+08</td>\n",
       "      <td>2017-01-29 23:20:09+00:00</td>\n",
       "      <td></td>\n",
       "      <td>8.258460e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @jokesuk: Anyone had to deal with erectile ...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>8.258460e+17</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '8212702208410869...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '8212702208410869...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author id                 created_at geo            id lang  like_count  \\\n",
       "0  2.300559e+09  2017-01-29 23:59:55+00:00      8.258560e+17   en         0.0   \n",
       "1  1.670847e+08  2017-01-29 23:20:09+00:00      8.258460e+17   en         0.0   \n",
       "\n",
       "   quote_count  reply_count  retweet_count              source  \\\n",
       "0          0.0          0.0            0.0  Twitter for iPhone   \n",
       "1          0.0          0.0           34.0  Twitter for iPhone   \n",
       "\n",
       "                                               tweet reply_settings  \\\n",
       "0           I have erectile dysfunction â˜¹ï¸_x008f_       everyone   \n",
       "1  RT @jokesuk: Anyone had to deal with erectile ...       everyone   \n",
       "\n",
       "   conversation_id                             referenced_tweets_type  \\\n",
       "0     8.258560e+17                                                NaN   \n",
       "1     8.258460e+17  [{'type': 'retweeted', 'id': '8212702208410869...   \n",
       "\n",
       "                                referenced_tweets_id  in_reply_to_user_id  \n",
       "0                                                NaN                  NaN  \n",
       "1  [{'type': 'retweeted', 'id': '8212702208410869...                  NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a53e1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=tweet[['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b765a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    I have erectile dysfunction â˜¹ï¸_x008f_\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d57034fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=tweet[tweet['tweet'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c57dfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['Tweet_exc_link']=tweet['tweet'].apply(lambda x: re.sub(r\"http\\S+\", \"\",x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1e438fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.to_csv(r'C:\\Users\\Revathi P\\Documents\\Graduate Research - Twitter Analysis\\Datasets\\Archive\\chk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f88899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
